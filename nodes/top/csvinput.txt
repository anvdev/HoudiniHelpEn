= CSV Input =

#type:      node
#context:   top
#internal:  csvinput
#icon:      TOP/csvinput

"""Copies data from a CSV file into work item attributes."""


== Overview ==

This node will create a work item for each row in the input CSV file (but see the __Limit rows__ parameter). It will extract data from certain columns you specify into attributes on the work items, or all columns automatically.

This can be useful to allow users to specify a list of work to do.

The opposite of this node (write attributes on work items into a CSV file) is the [CSV Output node|Node:csvoutput].


== How to ==

By default, if this node has input files, it creates a work item for each incoming row, _but it does not extract any data_. You need to decide how to provide it with CSV data, and specify which columns to extract.

# *Specify where to get the CSV data*. Do one of the following:

    * If you the input work items have CSV files in their result data, select __Upstream Result Files__.

        For example, if you get a list of files using a [File Pattern node|Node:top/filepattern], you should add a [Wait for All|Node:top/waitforall] after the file pattern, and then wire the Wait for All into this node. Assuming the File Pattern node only matches `*.csv` files, set it to tag its output files as `file/csv`. Finally, on the CSV Input node, select __Upstream Result Files__.

    * If you want to statically read in _one_ CSV file, select __Custom File Path__ and set the __File Path__ to the path of the static CSV file.

# *Choose what to extract*. Do one of the following:

    * If you want to extract data from individual columns, use the __Columns to Extract__ multiparm to specify the columns to extract and the attribute names to use. If your CSV file has a header row, turn on __Has Header Row__ to tell the node to _ignore_ it instead of using it as data.

    * If you want to extract all columns, turn on __Extract all__. If your CSV file has a header row, turn on __Has Header Row__ to tell the node to _use_ the header row to name the attributes. If the CSV file has no header, the node will make up attribute names like `column_0`, `column_1`, and so on.

    Using __Extract all__ extracts all values as *strings*. If you want to properly type numbers in the CSV file, you must extract columns manually instead.

# You can try generating the items in the node and check their attributes.


== Notes ==

* If there are multiple input files (from upstream item result paths), this node creates separate work items for each row of each file (however set __Limit Rows__).

* To ensure you can cook the network on a render farm, make sure the input CSV files are in the shared network filesystem.

@top_attributes

::`csv_rowindex`
    #type: integer

    The index of the row in the CSV file that the work item is created from.  This is 0-based, and does not include the header row if there is one.

:: `csv_columns`
    #type: string array

    An array of the names of attributes that were extracted from the CSV row.  This attribute is optionally created, and can be used by [Node:top/csvoutput].

@parameters

== Input ==

File:
    #id: useparent
    How do decide what file(s) to delete:

    Custom File Path:
        Specify the path of a single CSV file to load from (this field does not support file patterns).

    Upstream Result Files:
        Use the `output` file paths of the incoming work items as the file(s) to load. If you specify a [file tag|/tops/filetags] (usually `file/csv`), the node will only use files with that tag.

File Path:
    #id: csvfilepath

    When __Custom File Path__ is selected, specify the path of a single CSV file to load from (this field does not support file patterns).

Result Tag:
    #id: useparenttag

    When __File__ is "Upstream Result Files", delete paths in the `output` attributes of incoming work items if they have this [file tag|/tops/filetags].

Has Header Row:
    #id: hasheaderrow

    Turn this on if your CSV file(s) has/have a header row (containing column names). If you extract individual rows, the node uses this to ignore the header row (otherwise it will take it as data). If you select __Extract all__, the node will use the header to name the attributes.

Limit Rows:
    #id: limitrowcount

    Artificially limit the number of work items this node creates. The node reads the input rows sequentially as usual but simply stops at the given number of work items. This might be useful if you're worried about huge CSV files might be produced accidentally by a runaway process, or if CSV files are generated by humans and there's a convention that they may not contain more than a certain number of items. However, you should remember that this setting can make the node silently discard legitimate data.

Work Item Index:
    #id: indexmode

    Select how work item indexes are set when generating from an upstream item.

    Row Index:
        Use the CSV row index as the work item index.

    Upstream Index:
        Use the upstream item's index.

Column Delimiter:
    #id: delimiter

    Turn this on to explicitly set the column-separation character. If this is not turned on, the node will try guess the delimiter character from the first few rows of the file.

Add Columns Attribute:
    #id: columnorderattrname

    Turn this on to specify the name of a string array attribute that will be created to store the names of the columns that are extracted from the CSV.  The order of the names will match the columsn in the CSV.  This can be used in [Node:top/csvouput]

Extraction:
    #id: extractall

    Select the method of specifying column extractions.

    By Column Index:
        You will specify the 0-based index of columns to be extracted in __Columns to Extract__.

    All:
        When this is on, the node copies all columns into work item attributes. The attributes created are always string attributes. If you want to properly type numeric data, you should use another mode and extract columns "manually". If __Has header row__ is on, the node uses the column headers to name the attributes. If __Has Header Row__ is off, the node will make up attribute names like `column_0`, `column_1`, and so on.

    By Column Name:
        You will specify the header name of the columns to be extracted in __Columns to Extract__.

    By Attribute:
        You will supply the name of an attribute to read column names or indexes from in __Input Columns Attribute__.

Input Columns Attribute:
    #id: extractbyattrattr

    When __Extraction__ is set to __By Attribute__, specify the name of an attribute to read column names or index from.
    This attribute can be a string or integer array.  Column names must match the header in the CSV file, and indexes are 0-based from left to right.

Columns to Extract:
    #id: extractmult

    When __Extraction__ is set to __By Column Index__ or __By Column Name__, use this multiparm to set up mappings between input column names or indexes to and attribute names/types.

CSV Column Index:
    #id: extractrow#

    The column number to read the data from. The first column is number `0`, the second column is number `1`, and so on.

CSV Column Name:
    #id: extractcolumnname#

    The column header name from the CSV file to read data from.

Attribute Name:
    #id: extracttag#

    The name of the attribute to assign the value to.

Value Index:
    #id: extractindex#

    Attributes can have multiple values (to accomodate vectors and lists). You can set this to control at what position the value is inserted in the attribute value list.

Type:
    #id: extracttype#

    The data type of the extracted value (string, integer, or float).


== Processor ==

[Include:processor_common#pdg_workitemgeneration]


@related

- [Node:top/csvoutput]
- [Node:top/texttocsv]
